{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP/Z1IZLM55Vu1ndWaTVONw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kibet14isaac/AI-TOOLS/blob/main/AGRicu_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UInuCWJL35c2"
      },
      "outputs": [],
      "source": [
        "# src/data_preprocessing.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove punctuation\n",
        "    # Add more cleaning specific to local dialects/slang\n",
        "    return text\n",
        "\n",
        "def load_and_process_queries(filepath):\n",
        "    df = pd.read_csv(filepath) # Assuming CSV with 'query', 'intent', 'entities'\n",
        "    df['cleaned_query'] = df['query'].apply(clean_text)\n",
        "    # Further processing: tokenization, intent/entity labeling\n",
        "    return df\n",
        "\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    # Using Pillow or OpenCV\n",
        "    from PIL import Image\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img = img.resize(target_size)\n",
        "    img_array = np.array(img) / 255.0 # Normalize pixel values\n",
        "    return img_array\n",
        "\n",
        "# src/nlp_model.py\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "import torch\n",
        "\n",
        "class AgriculturalNLU:\n",
        "    def __init__(self, model_name=\"bert-base-uncased\", num_intents=5, num_entities=10):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        # For intent classification\n",
        "        self.intent_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_intents)\n",
        "        # For entity recognition (NER) - requires a different head\n",
        "        # self.entity_model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=num_entities)\n",
        "        # Load fine-tuned weights here if available\n",
        "        # self.intent_model.load_state_dict(torch.load(\"models/intent_model.pth\"))\n",
        "\n",
        "    def predict_intent(self, text):\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.intent_model(**inputs)\n",
        "        # Get predicted intent (e.g., \"pest_identification\", \"fertilizer_advice\")\n",
        "        return torch.argmax(outputs.logits).item() # Map to actual intent label\n",
        "\n",
        "    # Add predict_entities method\n",
        "    # Add a RAG component that integrates with a knowledge base\n",
        "\n",
        "# src/cv_model.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class PlantDiseaseClassifier:\n",
        "    def __init__(self, num_classes=20, input_shape=(224, 224, 3)):\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "        x = base_model.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(1024, activation='relu')(x)\n",
        "        predictions = Dense(num_classes, activation='softmax')(x)\n",
        "        self.model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        # Load fine-tuned weights here\n",
        "        # self.model.load_weights(\"models/cv_model_weights.h5\")\n",
        "\n",
        "    def train(self, train_data, val_data, epochs=10, batch_size=32):\n",
        "        self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        self.model.fit(train_data, validation_data=val_data, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    def predict(self, image_array):\n",
        "        # image_array should be preprocessed (resized, normalized)\n",
        "        return self.model.predict(np.expand_dims(image_array, axis=0)) # Returns probabilities\n",
        "\n",
        "# src/chatbot_logic.py\n",
        "from src.nlp_model import AgriculturalNLU\n",
        "from src.cv_model import PlantDiseaseClassifier\n",
        "# Assuming a simple knowledge base for demonstration\n",
        "knowledge_base = {\n",
        "    \"pest_identification\": {\n",
        "        \"maize_armyworm\": \"Symptoms: Ragged holes in leaves, faecal pellets. Control: Use 'Green Guard' pesticide or neem extract. See more at KALRO website.\",\n",
        "        \"potato_late_blight\": \"Symptoms: Brown/black lesions on leaves and stems, white mold on underside. Control: Apply copper-based fungicide or resistant varieties. Check weather for humidity.\",\n",
        "    },\n",
        "    \"fertilizer_advice\": {\n",
        "        \"maize\": \"For maize, use DAP at planting and CAN for top dressing. Soil test recommended for precise amounts.\",\n",
        "        \"kale\": \"Kale needs nitrogen-rich fertilizer. Use urea or manure.\",\n",
        "    },\n",
        "    \"weather_forecast\": {\n",
        "        \"default\": \"Please provide your county for a localized weather forecast.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "class AgriculturalChatbot:\n",
        "    def __init__(self):\n",
        "        self.nlu = AgriculturalNLU()\n",
        "        self.cv_classifier = PlantDiseaseClassifier()\n",
        "        # Initialize knowledge base for RAG (e.g., a Faiss index or simple dict)\n",
        "\n",
        "    def process_text_query(self, query, farmer_context={}):\n",
        "        intent_id = self.nlu.predict_intent(query)\n",
        "        # Map intent_id to intent_name\n",
        "        intent_name = self.nlu.get_intent_name(intent_id) # Assume this method exists\n",
        "\n",
        "        # Extract entities like crop, location, symptoms\n",
        "        # entities = self.nlu.predict_entities(query)\n",
        "\n",
        "        response = \"I'm sorry, I couldn't understand that. Could you please rephrase?\"\n",
        "\n",
        "        if intent_name == \"pest_identification\":\n",
        "            # Example: Search knowledge base for pest/disease information\n",
        "            if \"maize\" in query and \"armyworm\" in query:\n",
        "                response = knowledge_base[\"pest_identification\"][\"maize_armyworm\"]\n",
        "            else:\n",
        "                response = \"Please describe the symptoms or upload an image for pest/disease identification.\"\n",
        "        elif intent_name == \"fertilizer_advice\":\n",
        "            if \"maize\" in query:\n",
        "                response = knowledge_base[\"fertilizer_advice\"][\"maize\"]\n",
        "            else:\n",
        "                response = \"Which crop are you asking about for fertilizer?\"\n",
        "        elif intent_name == \"weather_forecast\":\n",
        "            # Call weather API based on farmer's stored location or extracted entity\n",
        "            # For this example, just a generic response\n",
        "            if 'county' in farmer_context:\n",
        "                response = f\"Fetching weather for {farmer_context['county']}... (placeholder for API call)\"\n",
        "            else:\n",
        "                response = knowledge_base[\"weather_forecast\"][\"default\"]\n",
        "\n",
        "        # Implement RAG logic: Retrieve relevant docs from knowledge base and pass to LLM for coherent response.\n",
        "        # This is where the LLM integration would happen, synthesizing info.\n",
        "\n",
        "        return response\n",
        "\n",
        "    def process_image_query(self, image_array):\n",
        "        prediction = self.cv_classifier.predict(image_array)\n",
        "        # Map prediction to disease/pest name and retrieve advice from knowledge base\n",
        "        disease_name = self.cv_classifier.get_disease_name(prediction) # Assume this\n",
        "        advice = knowledge_base[\"pest_identification\"].get(disease_name, \"Could not find specific advice for this. Please consult an extension officer.\")\n",
        "        return f\"Based on the image, it appears to be: {disease_name}. Advice: {advice}\"\n",
        "\n",
        "# src/api.py (Example using Flask or FastAPI for WhatsApp/SMS integration)\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "chatbot = AgriculturalChatbot()\n",
        "\n",
        "@app.route('/webhook', methods=['POST'])\n",
        "def webhook():\n",
        "    data = request.json # This will vary based on WhatsApp Business API/Twilio\n",
        "\n",
        "    # Extract message and sender ID\n",
        "    sender_id = data.get('from')\n",
        "    message_type = data.get('type') # 'text' or 'image'\n",
        "\n",
        "    if message_type == 'text':\n",
        "        user_message = data.get('text', {}).get('body')\n",
        "        # Simulate farmer context from a database\n",
        "        farmer_context = {\"county\": \"Nakuru\"} # Load from DB based on sender_id\n",
        "        response = chatbot.process_text_query(user_message, farmer_context)\n",
        "    elif message_type == 'image':\n",
        "        image_url = data.get('image', {}).get('url')\n",
        "        # Download image, preprocess it, then pass to CV model\n",
        "        # For simplicity, skipping download and processing here\n",
        "        # image_array = preprocess_image_from_url(image_url)\n",
        "        # response = chatbot.process_image_query(image_array)\n",
        "        response = \"Image analysis feature coming soon! Please describe the symptoms for now.\"\n",
        "    else:\n",
        "        response = \"I can only process text and images at the moment.\"\n",
        "\n",
        "    # Send response back via WhatsApp Business API / Twilio\n",
        "    # This involves making a POST request to their API\n",
        "    # For now, just return it as JSON for demonstration\n",
        "    return jsonify({\"reply\": response})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # For development, run with Flask's built-in server\n",
        "    app.run(debug=True, port=5000)\n",
        "    # For production, use Gunicorn or similar WSGI server"
      ]
    }
  ]
}